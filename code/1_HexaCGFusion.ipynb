{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "amino_acids_single_letter = ['C', 'D', 'S', 'Q', 'K', 'I', 'P', 'T', 'F', 'N', 'G', 'H', 'L', 'R', 'W', 'A', 'V', 'E', 'Y', 'M']\n",
    "alpha = [0.74, 0.89, 0.82, 1.29, 1.11, 1.04, 0.5, 0.76, 1.01, 0.77, 0.47, 0.92, 1.32, 5.03, 1.06, 1.39, 0.89, 1.35, 0.99, 1.21]\n",
    "beta = [1.31, 0.55, 0.85, 0.76, 0.83, 1.71, 0.44, 1.23, 1.43, 0.62, 0.65, 0.99, 1.1, 0.91, 1.3, 0.75, 1.86, 0.72, 1.5, 0.99]\n",
    "coil = [1.05, 1.33, 1.24, 0.89, 1, 0.59, 1.72, 1.07, 0.76, 1.39, 1.62, 1.07, 0.68, 0.91, 0.79, 0.8, 0.64, 1.33, 0.78, 0.83]\n",
    "hb_d = [0.769, 0.511, 0.56, 0.675, 0.662, 0.834, 0, 0.597, 0.764, 0.587, 0.619, 0.662, 0.836, 0.698, 0.719, 0.726, 0.798, 0.574, 0.749, 0.77]\n",
    "hb_a = [0.705, 0.623, 0.595, 0.366, 0.6, 0.878, 0.477, 0.637, 0.724, 0.58, 0.502, 0.658, 0.745, 0.659, 0.733, 0.648, 0.77, 0.929, 0.731, 0.715]\n",
    "hi = [2.5, -3.5, -0.8, -3.5, -3.9, 4.5, -1.6, -0.7, 2.8, -3.5, -0.4, -3.2, 3.8, -4.5, -0.9, 1.8, 4.2, -3.5, -1.3, 1.9]\n",
    "PD = [23.99, 17.39, 18.35, 17.43, 17.72, 25.96, 17.53, 19.91, 27.42, 18.57, 17.18, 21.64, 25.53, 21.03, 28.53, 19.97, 24.05, 19.19, 26.17, 24.8]\n",
    "DM = [10.74, 29.49, 9.836, 39.89, 50.02, 3.371, 7.916, 9.304, 5.98, 18.89, 0, 20.44, 3.782, 37.5, 10.73, 5.937, 2.692, 42.52, 10.41, 8.589]\n",
    "\n",
    "train_df = pd.read_csv(r'./train.csv')\n",
    "test_df = pd.read_csv(r'.test.csv')\n",
    "\n",
    "def one_hot_encode(seq):\n",
    "    amino_acids = 'CDSQKIPTFNGHLRWAVEYM'\n",
    "    aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}\n",
    "    one_hot = np.zeros((len(seq), len(amino_acids)))\n",
    "    for i, aa in enumerate(seq):\n",
    "        one_hot[i, aa_to_index[aa]] = 1\n",
    "    return one_hot\n",
    "\n",
    "try:\n",
    "    train_df['OneHot'] = train_df['Sequence'].apply(one_hot_encode)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    test_df['OneHot'] = test_df['Sequence'].apply(one_hot_encode)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    \n",
    "expanded_arrays = train_df['OneHot'].apply(lambda x: np.array(x))\n",
    "X_train = np.array(expanded_arrays.tolist())\n",
    "y_train = train_df['label']\n",
    "\n",
    "expanded_arrays = test_df['OneHot'].apply(lambda x: np.array(x))\n",
    "X_test = np.array(expanded_arrays.tolist())\n",
    "y_test = test_df['label']\n",
    "\n",
    "print('train_x', X_train.shape)\n",
    "print('test_x', X_test.shape)\n",
    "\n",
    "amino_acid_to_alpha = dict(zip(amino_acids_single_letter, alpha))\n",
    "amino_acid_to_beta = dict(zip(amino_acids_single_letter, beta))\n",
    "amino_acid_to_coil = dict(zip(amino_acids_single_letter, coil))\n",
    "amino_acid_to_hb_d = dict(zip(amino_acids_single_letter, hb_d))\n",
    "amino_acid_to_hb_a = dict(zip(amino_acids_single_letter, hb_a))\n",
    "amino_acid_to_hi = dict(zip(amino_acids_single_letter, hi))\n",
    "amino_acid_to_PD = dict(zip(amino_acids_single_letter, PD))\n",
    "amino_acid_to_DM = dict(zip(amino_acids_single_letter, DM))\n",
    "\n",
    "train_df['alpha'] = train_df['Sequence'].apply(lambda seq: [amino_acid_to_alpha[aa] for aa in seq])\n",
    "test_df['alpha'] = test_df['Sequence'].apply(lambda seq: [amino_acid_to_alpha[aa] for aa in seq])\n",
    "train_df['beta'] = train_df['Sequence'].apply(lambda seq: [amino_acid_to_beta[aa] for aa in seq])\n",
    "test_df['beta'] = test_df['Sequence'].apply(lambda seq: [amino_acid_to_beta[aa] for aa in seq])\n",
    "train_df['coil'] = train_df['Sequence'].apply(lambda seq: [amino_acid_to_coil[aa] for aa in seq])\n",
    "test_df['coil'] = test_df['Sequence'].apply(lambda seq: [amino_acid_to_coil[aa] for aa in seq])\n",
    "train_df['hb_d'] = train_df['Sequence'].apply(lambda seq: [amino_acid_to_hb_d[aa] for aa in seq])\n",
    "test_df['hb_d'] = test_df['Sequence'].apply(lambda seq: [amino_acid_to_hb_d[aa] for aa in seq])\n",
    "train_df['hb_a'] = train_df['Sequence'].apply(lambda seq: [amino_acid_to_hb_a[aa] for aa in seq])\n",
    "test_df['hb_a'] = test_df['Sequence'].apply(lambda seq: [amino_acid_to_hb_a[aa] for aa in seq])\n",
    "train_df['hi'] = train_df['Sequence'].apply(lambda seq: [amino_acid_to_hi[aa] for aa in seq])\n",
    "test_df['hi'] = test_df['Sequence'].apply(lambda seq: [amino_acid_to_hi[aa] for aa in seq])\n",
    "train_df['PD'] = train_df['Sequence'].apply(lambda seq: [amino_acid_to_PD[aa] for aa in seq])\n",
    "test_df['PD'] = test_df['Sequence'].apply(lambda seq: [amino_acid_to_PD[aa] for aa in seq])\n",
    "train_df['DM'] = train_df['Sequence'].apply(lambda seq: [amino_acid_to_DM[aa] for aa in seq])\n",
    "test_df['DM'] = test_df['Sequence'].apply(lambda seq: [amino_acid_to_DM[aa] for aa in seq])\n",
    "\n",
    "alpha_train = np.array(train_df['alpha'].tolist()).reshape(-1, 6, 1)\n",
    "alpha_test = np.array(test_df['alpha'].tolist()).reshape(-1, 6, 1)\n",
    "beta_train = np.array(train_df['beta'].tolist()).reshape(-1, 6, 1)\n",
    "beta_test = np.array(test_df['beta'].tolist()).reshape(-1, 6, 1)\n",
    "coil_train = np.array(train_df['coil'].tolist()).reshape(-1, 6, 1)\n",
    "coil_test = np.array(test_df['coil'].tolist()).reshape(-1, 6, 1)\n",
    "hb_d_train = np.array(train_df['hb_d'].tolist()).reshape(-1, 6, 1)\n",
    "hb_d_test = np.array(test_df['hb_d'].tolist()).reshape(-1, 6, 1)\n",
    "hb_a_train = np.array(train_df['hb_a'].tolist()).reshape(-1, 6, 1)\n",
    "hb_a_test = np.array(test_df['hb_a'].tolist()).reshape(-1, 6, 1)\n",
    "hi_train = np.array(train_df['hi'].tolist()).reshape(-1, 6, 1)\n",
    "hi_test = np.array(test_df['hi'].tolist()).reshape(-1, 6, 1)\n",
    "PD_train = np.array(train_df['PD'].tolist()).reshape(-1, 6, 1)\n",
    "PD_test = np.array(test_df['PD'].tolist()).reshape(-1, 6, 1)\n",
    "DM_train = np.array(train_df['DM'].tolist()).reshape(-1, 6, 1)\n",
    "DM_test = np.array(test_df['DM'].tolist()).reshape(-1, 6, 1)\n",
    "\n",
    "X_train_feature = np.concatenate((alpha_train, beta_train, coil_train, hb_d_train, hb_a_train, hi_train, PD_train, DM_train), axis=2)\n",
    "X_test_feature = np.concatenate((alpha_test, beta_test, coil_test, hb_d_test, hb_a_test, hi_test, PD_test, DM_test), axis=2)\n",
    "print('train_x_feature', X_train_feature.shape)\n",
    "print('test_x_feature', X_test_feature.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_x_reshaped = X_train_feature.reshape(-1, X_train_feature.shape[-1])\n",
    "test_x_reshaped = X_test_feature.reshape(-1, X_test_feature.shape[-1])\n",
    "scaler.fit(train_x_reshaped)\n",
    "train_x_standardized = scaler.transform(train_x_reshaped)\n",
    "test_x_standardized = scaler.transform(test_x_reshaped)\n",
    "train_x_standardized = np.round(train_x_standardized.reshape(X_train_feature.shape), 2)\n",
    "test_x_standardized = np.round(test_x_standardized.reshape(X_test_feature.shape), 2)\n",
    "train_x_standardized = train_x_standardized.reshape(X_train_feature.shape)\n",
    "test_x_standardized = test_x_standardized.reshape(X_test_feature.shape)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_x_reshaped = train_x_standardized.reshape(-1, X_train_feature.shape[-1])\n",
    "test_x_reshaped = test_x_standardized.reshape(-1, X_test_feature.shape[-1])\n",
    "min_max_scaler.fit(train_x_reshaped)\n",
    "train_x_normalized = min_max_scaler.transform(train_x_reshaped)\n",
    "test_x_normalized = min_max_scaler.transform(test_x_reshaped)\n",
    "train_x_normalized = np.round(train_x_normalized.reshape(X_train_feature.shape), 2)\n",
    "test_x_normalized = np.round(test_x_normalized.reshape(X_test_feature.shape), 2)\n",
    "train_x_normalized = train_x_normalized.reshape(X_train_feature.shape)\n",
    "test_x_normalized = test_x_normalized.reshape(X_test_feature.shape)\n",
    "print(train_x_normalized.shape)\n",
    "print(test_x_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_matrix = np.concatenate((X_train, train_x_normalized),axis = 2)\n",
    "X_test_matrix = np.concatenate((X_test, test_x_normalized),axis = 2)\n",
    "print(X_train_matrix.shape)\n",
    "print(X_test_matrix.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2832365f9ae5bae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import GRU, Conv1D, BatchNormalization, Activation, MaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "\n",
    "epoch = 100\n",
    "checkpoint = ModelCheckpoint(filepath=f'./check_point/stage_one.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(6, 28)),\n",
    "    Dense(168),\n",
    "    Conv1D(64,(3),strides = (1),padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D((3),padding=\"same\"),\n",
    "    GRU(units=64, return_sequences=True, recurrent_dropout=0.2),\n",
    "    GRU(units=32, return_sequences=True, recurrent_dropout=0.2),\n",
    "    GRU(units=16, return_sequences=False),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_matrix, y_train, batch_size=512, epochs = epoch,validation_split=0.2, callbacks=[checkpoint, early_stopping])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7d97e3b83781d89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
